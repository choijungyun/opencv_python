import urllib
from urllib import request
from urllib.request import urlopen
import cv2
import numpy as np
import math
import requests
import json
from bs4 import BeautifulSoup

# opener
opener = urllib.request.build_opener()
opener.addheaders = [('User-Agent',
                      'Mozilla/5.0 (Windows NT 6.1; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/36.0.1941.0 Safari/537.36')]
urllib.request.install_opener(opener)

# image.php를 통해 dbms에 저장된 이미지의 path를 가져옴
path = "http://203.252.195.136/mm_image.php"
html_result = requests.get(path).text
decoded = json.loads(html_result, encoding='utf-8')
image_full_path = []
image_short_path = []
# 가져온 image path를 image_full_path array에 저장
for x in decoded['result']:
    image_path = x['path']
    image_full_path.append("http://203.252.195.136" + image_path)
    image_short_path.append(image_path)

#path_string = image_full_path[3]
#path_string_2 = image_full_path[4]
#path_string_3 = image_full_path[5]
#path_string_4 = image_full_path[2]
#path_string_button = image_full_path[0]
# cv2.imread(path, -1) 부분을 대신하는 코드
#url_response = urllib.request.urlopen(image_full_path[0])
#url_response2 = urllib.request.urlopen(path_string_2)
#url_response3 = urllib.request.urlopen(path_string_3)
#url_storage = urllib.request.urlopen(path_string_4)
#url_button = urllib.request.urlopen(path_string_button)
#img_array = np.array(bytearray(urllib.request.urlopen(image_full_path[3]).read()), dtype=np.uint8)
#img_array2 = np.array(bytearray(urllib.request.urlopen(image_full_path[4]).read()), dtype=np.uint8)
#img_array3 = np.array(bytearray(urllib.request.urlopen(image_full_path[5]).read()), dtype=np.uint8)
#first_dress_ori = cv2.imdecode(display_image_path[0], -1)

display_rightarrow_path = np.array(bytearray(urllib.request.urlopen(image_full_path[0]).read()), dtype=np.uint8)
display_leftarrow_path = np.array(bytearray(urllib.request.urlopen(image_full_path[1]).read()), dtype=np.uint8)
display_savebutton_path = np.array(bytearray(urllib.request.urlopen(image_full_path[2]).read()), dtype=np.uint8)

count = 0
display_image_path = []
for x in image_full_path:
    if count < 3:
        count = count+1
        continue
    else :
        display_image_path.append(np.array(bytearray(urllib.request.urlopen(image_full_path[count]).read()), dtype=np.uint8))
        count = count+1

select_img = display_image_path[0]
select_number = 0
#DB에서 비교할 변수
select_path = image_full_path[3]
# webcam 실행
cap = cv2.VideoCapture(0)
# webcam width, height 설정
cap.set(cv2.CAP_PROP_FRAME_WIDTH, 1280)
cap.set(cv2.CAP_PROP_FRAME_HEIGHT, 1024)

# face detect xml
face_cascade = cv2.CascadeClassifier('haarcascade_frontalface_default.xml')


# overlay
def transparentOverlay(src, overlay, pos=(0, 0), scale=1):
    overlay = cv2.resize(overlay, (0, 0), fx=scale, fy=scale)
    h, w, _ = overlay.shape
    rows, cols, _ = src.shape
    y, x = pos[0], pos[1]

    for i in range(h):
        for j in range(w):
            if x + i >= rows or y + j >= cols:
                continue
            alpha = float(overlay[i][j][3] / 255.0)
            src[x + i][y + j] = alpha * overlay[i][j][:3] + (1 - alpha) * src[x + i][y + j]
    return src

def dresswear(select_img_path):
    imgDress = cv2.imdecode(select_img_path, -1)
    orig_mask = imgDress[:, :, 3]
    orig_mask_inv = cv2.bitwise_not(orig_mask)
    imgDress = imgDress[:, :, 0:3]
    origLogoHeight, origLogoWidth = imgDress.shape[:2]

    dressWidth = 3 * face_w
    dressHeight = int(dressWidth * origLogoHeight / origLogoWidth)
    dress_x_start = face_x_end - int(face_w / 2) - int(dressWidth / 2)
    dress_x_end = dress_x_start + dressWidth
    dress_y_start = face_y_end + 5
    dress_y_end = dress_y_start + dressHeight

    dressWidth = dress_x_end - dress_x_start
    dressHeight = dress_y_end - dress_y_start

    if dressWidth < 0 or dressHeight < 0:
        return

    dress = cv2.resize(imgDress, (dressWidth, dressHeight), interpolation=cv2.INTER_AREA)
    # adjust the image to fit into the camera image, to prevent window size overflow
    if dress_x_start < 0:
        dress_x_start = 0
    if dress_y_start < 0:
        dress_y_start = 0
    if dress_x_end > img_w:
        dress_x_end = img_w
    if dress_y_end > img_h:
        dress_y_end = img_h

    # calculate the cropped image size
    crop_dressWidth = dress_x_end - dress_x_start
    crop_dressHeight = dress_y_end - dress_y_start
    # print("w=%d, h=%d, cw=%d, ch=%d" % (dressWidth, dressHeight, crop_dressWidth, crop_dressHeight))

    # resize the original dress mask with the current enlarged image size
    mask = cv2.resize(orig_mask, (dressWidth, dressHeight), interpolation=cv2.INTER_AREA)
    mask_inv = cv2.resize(orig_mask_inv, (dressWidth, dressHeight), interpolation=cv2.INTER_AREA)
    # print("x1=%d, y1=%d, x2=%d, y2=%d" % (shirt_x1, shirt_y1, shirt_x2, shirt_y2))

    mask = mask[0:crop_dressHeight, 0:crop_dressWidth]
    mask_inv = mask_inv[0:crop_dressHeight, 0:crop_dressWidth]

    # cv2.imshow("mask", mask)
    # cv2.imshow("mask_inv", mask_inv)

    crop_dress = dress[0:crop_dressHeight, 0:crop_dressWidth]
    roi = img[dress_y_start:dress_y_end, dress_x_start:dress_x_end]
    roi_bg = cv2.bitwise_and(roi, roi, mask=mask_inv)
    roi_fg = cv2.bitwise_and(crop_dress, crop_dress, mask=mask)
    dst = cv2.add(roi_bg, roi_fg)
    img[dress_y_start:dress_y_end, dress_x_start:dress_x_end] = dst

def showimg(src, dress_x_size, dress_y_size, dress_x_start, dress_x_end, dress_y_start, dress_y_end):
    Recommend = cv2.imdecode(src, -1)
    Recommend_orig_mask = Recommend[:, :, 3]
    Recommend_orig_mask_inv = cv2.bitwise_not(Recommend_orig_mask)
    Recommend = Recommend[:, :, 0:3]
    RecommendLogoHeight, RecommendLogoWidth = Recommend.shape[:2]
    Recommend_dress = cv2.resize(Recommend, (dress_x_size, dress_y_size), interpolation=cv2.INTER_AREA)
    Recommend_mask = cv2.resize(Recommend_orig_mask, (dress_x_size, dress_y_size), interpolation=cv2.INTER_AREA)
    Recommend_mask_inv = cv2.resize(Recommend_orig_mask_inv, (dress_x_size, dress_y_size), interpolation=cv2.INTER_AREA)
    Recommend_roi = img[dress_y_start:dress_y_end, dress_x_start:dress_x_end]
    Recommend_roi_bg = cv2.bitwise_and(Recommend_roi, Recommend_roi, mask=Recommend_mask_inv)
    cv2.imshow("second", Recommend_mask)
    cv2.imshow("second_inv", Recommend_mask_inv)
    Recommend_roi_fg = cv2.bitwise_and(Recommend_dress, Recommend_dress, mask=Recommend_mask)
    Recommend_dst = cv2.add(Recommend_roi_bg, Recommend_roi_fg)
    img[dress_y_start:dress_y_end, dress_x_start:dress_x_end] = Recommend_dst

def detecthand(crop_detectplace):
    grey = cv2.cvtColor(crop_detectplace, cv2.COLOR_BGR2GRAY)
    value = (35, 35)
    blurred = cv2.GaussianBlur(grey, value, 0)
    # thresholdin: Otsu's Binarization method
    _, thresh1 = cv2.threshold(blurred, 127, 255,
                               cv2.THRESH_BINARY_INV + cv2.THRESH_OTSU)
    # check OpenCV version to avoid unpacking error
    (version, _, _) = cv2.__version__.split('.')

    if version == '3':
        image, contours, hierarchy = cv2.findContours(thresh1.copy(), \
                                                      cv2.RETR_TREE, cv2.CHAIN_APPROX_NONE)
    elif version == '2':
        contours, hierarchy = cv2.findContours(thresh1.copy(), cv2.RETR_TREE, \
                                               cv2.CHAIN_APPROX_NONE)

    # find contour with max area
    cnt = max(contours, key=lambda x: cv2.contourArea(x))

    # create bounding rectangle around the contour (can skip below two lines)
    x, y, w, h = cv2.boundingRect(cnt)
    cv2.rectangle(crop_detectplace, (x, y), (x + w, y + h), (255, 0, 255), 0)

    # finding convex hull
    hull = cv2.convexHull(cnt)

    # drawing contours
    drawing = np.zeros(crop_detectplace.shape, np.uint8)

    cv2.drawContours(drawing, [cnt], 0, (0, 255, 0), 0)
    cv2.drawContours(drawing, [hull], 0, (0, 0, 255), 0)

    # finding convex hull
    hull = cv2.convexHull(cnt, returnPoints=False)

    # finding convexity defects
    defects = cv2.convexityDefects(cnt, hull)
    count_defects = 0
    cv2.drawContours(thresh1, contours, -1, (0, 255, 0), 3)

    # applying Cosine Rule to find angle for all defects (between fingers)
    # with angle > 90 degrees and ignore defects
    for i in range(defects.shape[0]):
        s, e, f, d = defects[i, 0]

        start = tuple(cnt[s][0])
        end = tuple(cnt[e][0])
        far = tuple(cnt[f][0])

        # find length of all sides of triangle
        a = math.sqrt((end[0] - start[0]) ** 2 + (end[1] - start[1]) ** 2)
        b = math.sqrt((far[0] - start[0]) ** 2 + (far[1] - start[1]) ** 2)
        c = math.sqrt((end[0] - far[0]) ** 2 + (end[1] - far[1]) ** 2)

        # apply cosine rule here
        angle = math.acos((b ** 2 + c ** 2 - a ** 2) / (2 * b * c)) * 57

        # ignore angles > 90 and highlight rest with red dots
        if angle <= 90:
            count_defects += 1
            cv2.circle(crop_detectplace, far, 1, [0, 0, 255], -1)

        # dist = cv2.pointPolygonTest(cnt,far,True)

        # draw a line from start to end i.e. the convex points (finger tips)
        # (can skip this part)
        cv2.line(crop_detectplace, start, end, [0, 255, 0], 2)
        # cv2.circle(crop_img,far,5,[0,0,255],-1)
        if count_defects >= 1:
            return True

# store the previous face coordinate
prev_fx = 0
prev_fy = 0
prev_fw = 0
prev_fh = 0

while (cap.isOpened()):
    # read image
    ret, img = cap.read()
    img_h, img_w = img.shape[:2]
    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)
    # webcam flip (좌우 반전)
    if ret == True:
        img = cv2.flip(img, 1)
    # get hand data from the rectangle sub window on the screen

    faces = face_cascade.detectMultiScale(gray, 1.3, 5)

    # detect된 face의 좌표
    fx = 0;
    fy = 0;
    fw = 0;
    fh = 0

    # 10 범위 내에서 변경 없도록 설정
    for (fx, fy, fw, fh) in faces:
        if ((abs(prev_fx - fx) > 10) and (abs(prev_fy - fy) > 10)):
            prev_fx = fx;
            prev_fy = fy;
            prev_fw = fw;
            prev_fh = fh;
        else:
            fx = prev_fx;
            fy = prev_fy;
            fw = prev_fw;
            fh = prev_fh;

        face_w = fw
        face_h = fh
        face_x_start = img_w - fx - face_w
        face_x_end = face_x_start + face_w
        face_y_start = fy
        face_y_end = face_y_start + face_h

        dresswear(select_img)
        break

    #showimg(display_image_path[0], 60, 200, 50, 110, 10, 210)
    #showimg(display_image_path[1], 60, 200, 190, 250, 10, 210)
    #showimg(display_image_path[2], 60, 200, 430, 490, 10, 210)
    showimg(display_savebutton_path, 60, 60, 610, 670, 50, 110)
    showimg(display_rightarrow_path, 60, 60, 825, 885, 300, 360)
    showimg(display_leftarrow_path, 60, 60, 455, 515, 300, 360)

    # 얼굴 안잡힐 때 드레스 띄우는 코드 추가
    #face_first_dress_roi_color = img[100:300, 10:200]
    #first_dress = cv2.resize(first_dress_ori, (60, 200), interpolation=cv2.INTER_CUBIC)
    # transparentOverlay(face_first_dress_roi_color, first_dress)

    crop_righthand = img[250:400, 825:885]
    crop_lefthand = img[250:400, 450:510]
    crop_savebutton = img[50:120, 610:670]

    if detecthand(crop_righthand) == True:
        select_number = select_number + 1
        if select_number > 6:
            select_number = 6
        select_img = display_image_path[select_number]
        select_path = image_short_path[select_number+3]
        cv2.putText(img, "right arrow", (5, 50), cv2.FONT_HERSHEY_SIMPLEX, 1, 2)
    if detecthand(crop_lefthand) == True:
        select_number = select_number - 1
        if select_number < 0:
            select_number = 0
        select_img = display_image_path[select_number]
        select_path = image_short_path[select_number+3]
        cv2.putText(img, "left arrow", (5, 50), cv2.FONT_HERSHEY_SIMPLEX, 1, 2)
    if detecthand(crop_savebutton) == True:
        userdata = {"select_path": select_path}
        resp =requests.post("http://203.252.195.136/mm_save.php", data = userdata);
        cv2.putText(img, "save", (5, 50), cv2.FONT_HERSHEY_SIMPLEX, 1, 2)



    cv2.imshow('Gesture', img)

    if cv2.waitKey(20) & 0xFF == ord('q'):
        break